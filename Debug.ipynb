{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5600ea78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libs\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import logging\n",
    "import argparse\n",
    "import itertools\n",
    "\n",
    "from src.config import config\n",
    "from src.base import MatchPrior\n",
    "from src.network import create_network\n",
    "from src.multibox_loss import MultiboxLoss\n",
    "from src.open_images import OpenImagesDataset\n",
    "from src.data_preprocessing import TrainAugmentation, TestTransform\n",
    "from utils.misc import str2bool, Timer, freeze_net_layers, store_labels\n",
    "\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, MultiStepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78f2aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parser = argparse.ArgumentParser(description='Single Shot MultiBox Detector Training With PyTorch')\n",
    "\n",
    "# Params for datasets\n",
    "parser.add_argument('--datasets', '--data',    nargs='+', default=[\"data\"], help='Dataset directory path')\n",
    "parser.add_argument('--balance-data',          action='store_true', help=\"Balance training data by down-sampling more frequent labels.\")\n",
    "\n",
    "# Params for network\n",
    "parser.add_argument('--freeze-base-net',       action='store_true',help=\"Freeze base net layers.\")\n",
    "parser.add_argument('--freeze-net',            action='store_true',help=\"Freeze all the layers except the prediction head.\")\n",
    "parser.add_argument('--width-mult',            default=1.0, type=float, help='Width Multiplifier for network')\n",
    "\n",
    "# Params for loading pretrained basenet or checkpoints.\n",
    "parser.add_argument('--base-net',              help='Pretrained base model')\n",
    "parser.add_argument('--pretrained',            default='models/pretrained.pth', type=str, help='Pre-trained base model')\n",
    "parser.add_argument('--resume',                default=None, type=str,help='Checkpoint state_dict file to resume training from')\n",
    "\n",
    "# Params for SGD\n",
    "parser.add_argument('--lr', '--learning-rate', default=0.01, type=float,help='initial learning rate')\n",
    "parser.add_argument('--momentum',              default=0.9, type=float,help='Momentum value for optim')\n",
    "parser.add_argument('--weight-decay',          default=5e-4, type=float,help='Weight decay for SGD')\n",
    "parser.add_argument('--gamma',                 default=0.1, type=float,help='Gamma update for SGD')\n",
    "parser.add_argument('--base-net-lr',           default=0.001, type=float,help='initial learning rate for base net, or None to use --lr')\n",
    "parser.add_argument('--extra-layers-lr',       default=None, type=float,help='initial learning rate for the layers not in base net and prediction heads.')\n",
    "\n",
    "# Scheduler\n",
    "parser.add_argument('--scheduler',             default=\"cosine\", type=str,help=\"Scheduler for SGD. It can one of multi-step and cosine\")\n",
    "\n",
    "# Params for Multi-step Scheduler\n",
    "parser.add_argument('--milestones',            default=\"80,100\", type=str,help=\"milestones for MultiStepLR\")\n",
    "\n",
    "# Params for Cosine Annealing\n",
    "parser.add_argument('--t-max',                 default=100,  type=float,help='T_max value for Cosine Annealing Scheduler.')\n",
    "\n",
    "# Train params\n",
    "parser.add_argument('--batch-size',            default=16,    type=int,help='Batch size for training')\n",
    "parser.add_argument('--num-epochs',            default=100,   type=int,help='the number epochs')\n",
    "parser.add_argument('--num-workers',           default=4,    type=int, help='Number of workers used in dataloading')\n",
    "parser.add_argument('--validation-epochs',     default=5,    type=int,help='the number epochs between running validation')\n",
    "parser.add_argument('--debug-steps',           default=10,   type=int,help='Set the debug log output frequency.')\n",
    "parser.add_argument('--use-cuda',              default=True, type=str2bool,help='Use CUDA to train model')\n",
    "parser.add_argument('--checkpoint-folder',     default='models/', help='Directory for saving checkpoint models')\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n",
    "                    format='%(asctime)s - %(message)s', datefmt=\"%Y-%m-%d %H:%M:%S\")\n",
    "                    \n",
    "args   = parser.parse_args([])\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() and args.use_cuda else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8472db7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f021db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_net = lambda num: create_network(num, width_mult=args.width_mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889f7dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.image_size = 736\n",
    "print(config.priors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bc78c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.priors[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4558d23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform  = TrainAugmentation(config.image_size, config.image_mean, config.image_std)\n",
    "target_transform = MatchPrior(config.priors, config.center_variance,config.size_variance, 0.5)\n",
    "test_transform   = TestTransform(config.image_size, config.image_mean, config.image_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46922205",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.datasets = \"data/person_dog/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2937a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = OpenImagesDataset(args.datasets,\n",
    "                            transform        = train_transform, \n",
    "                            target_transform = target_transform,\n",
    "                            dataset_type     = \"train\",\n",
    "                            balance_data     = args.balance_data\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1664e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_file  = os.path.join(args.checkpoint_folder, \"labels.txt\")\n",
    "store_labels(label_file, dataset.class_names)\n",
    "logging.info(dataset)\n",
    "num_classes = len(dataset.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01aab410",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader  = DataLoader(dataset, \n",
    "                           args.batch_size,\n",
    "                           num_workers = args.num_workers,\n",
    "                           shuffle     = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e17b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "net        = create_net(num_classes)\n",
    "min_loss   = -10000.0\n",
    "last_epoch = -1\n",
    "\n",
    "# freeze certain layers (if requested)\n",
    "base_net_lr = args.base_net_lr if args.base_net_lr is not None else args.lr\n",
    "extra_layers_lr = args.extra_layers_lr if args.extra_layers_lr is not None else args.lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4da7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "        {'params': net.base_net.parameters(), 'lr': base_net_lr},\n",
    "        {'params': itertools.chain(\n",
    "            net.source_layer_add_ons.parameters(),\n",
    "            net.extras.parameters()\n",
    "        ), 'lr': extra_layers_lr},\n",
    "        {'params': itertools.chain(\n",
    "            net.regression_headers.parameters(),\n",
    "            net.classification_headers.parameters()\n",
    "        )}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda46805",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.init_from_pretrained(args.pretrained)\n",
    "net.train(True)\n",
    "net.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7dc5c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac531d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a774061",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(train_loader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0d3b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, boxes, labels = data\n",
    "images                = images.to(DEVICE)\n",
    "boxes                 = boxes.to(DEVICE)\n",
    "labels                = labels.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0c3178",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape, boxes.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b66a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence, locations = net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff4ed94",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence.shape, locations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0a8931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(train_loader, net, criterion, optimizer,\n",
    "#               device=DEVICE, debug_steps=args.debug_steps, epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1352b46e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761bb22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f218ed7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa71d3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "126a2569",
   "metadata": {},
   "source": [
    "### Train Pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25f2db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader, net, criterion, optimizer, device, debug_steps=100, epoch=-1):\n",
    "    net.train(True)\n",
    "    running_loss = 0.0\n",
    "    running_regression_loss = 0.0\n",
    "    running_classification_loss = 0.0\n",
    "    for i, data in enumerate(loader):\n",
    "        images, boxes, labels = data\n",
    "        images = images.to(device)\n",
    "        boxes = boxes.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        confidence, locations = net(images)\n",
    "        regression_loss, classification_loss = criterion(confidence, locations, labels, boxes)  # TODO CHANGE BOXES\n",
    "        loss = regression_loss + classification_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_regression_loss += regression_loss.item()\n",
    "        running_classification_loss += classification_loss.item()\n",
    "        if i and i % debug_steps == 0:\n",
    "            avg_loss = running_loss / debug_steps\n",
    "            avg_reg_loss = running_regression_loss / debug_steps\n",
    "            avg_clf_loss = running_classification_loss / debug_steps\n",
    "            logging.info(\n",
    "                f\"Epoch: {epoch}, Step: {i}/{len(loader)}, \" +\n",
    "                f\"Avg Loss: {avg_loss:.4f}, \" +\n",
    "                f\"Avg Regression Loss {avg_reg_loss:.4f}, \" +\n",
    "                f\"Avg Classification Loss: {avg_clf_loss:.4f}\"\n",
    "            )\n",
    "            running_loss = 0.0\n",
    "            running_regression_loss = 0.0\n",
    "            running_classification_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be44403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function and optimizer\n",
    "criterion = MultiboxLoss(config.priors, iou_threshold=0.5, neg_pos_ratio=3,\n",
    "                         center_variance=0.1, size_variance=0.2, device=DEVICE)\n",
    "optimizer = torch.optim.SGD(params, lr=args.lr, momentum=args.momentum,\n",
    "                            weight_decay=args.weight_decay)\n",
    "logging.info(f\"Learning rate: {args.lr}, Base net learning rate: {base_net_lr}, \"\n",
    "             + f\"Extra Layers learning rate: {extra_layers_lr}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d0787f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = CosineAnnealingLR(optimizer, args.t_max, last_epoch=last_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d3aa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(last_epoch + 1, args.num_epochs):\n",
    "    scheduler.step()\n",
    "    train(train_loader, net, criterion, optimizer,\n",
    "          device=DEVICE, debug_steps=args.debug_steps, epoch=epoch)\n",
    "    break\n",
    "\n",
    "#     if epoch % args.validation_epochs == 0 or epoch == args.num_epochs - 1:\n",
    "#         val_loss, val_regression_loss, val_classification_loss = test(val_loader, net, criterion, DEVICE)\n",
    "#         logging.info(\n",
    "#             f\"Epoch: {epoch}, \" +\n",
    "#             f\"Validation Loss: {val_loss:.4f}, \" +\n",
    "#             f\"Validation Regression Loss {val_regression_loss:.4f}, \" +\n",
    "#             f\"Validation Classification Loss: {val_classification_loss:.4f}\"\n",
    "#         )\n",
    "#         model_path = os.path.join(args.checkpoint_folder, f\"{args.net}-Epoch-{epoch}-Loss-{val_loss}.pth\")\n",
    "#         net.save(model_path)\n",
    "#         logging.info(f\"Saved model {model_path}\")\n",
    "\n",
    "# logging.info(\"Task done, exiting program.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89daa6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb629168",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(os.listdir(\"data/person_dog/train\")):\n",
    "    img = cv2.imread(\"data/person_dog/train/\"+i)\n",
    "    if len(img.shape)!=3:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e82726",
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1270fc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"data/person_dog/train/000000235832.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccf566b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc55f8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls data/person_dog/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9aaa067",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/person_dog/sub-train-annotations-bbox.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88143c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"ImageID\"]!= \"000000235832\"].to_csv('data/person_dog/sub-train-annotations-bbox.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37805432",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
