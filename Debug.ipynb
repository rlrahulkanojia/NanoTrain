{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eaa538",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Commands\n",
    "# python train.py --data data/person_dog "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4315d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5600ea78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libs\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import logging\n",
    "import argparse\n",
    "import itertools\n",
    "\n",
    "from src.config import config\n",
    "from src.base import MatchPrior\n",
    "from src.network import create_network\n",
    "from src.multibox_loss import MultiboxLoss\n",
    "from src.open_images import OpenImagesDataset\n",
    "from src.data_preprocessing import TrainAugmentation, TestTransform\n",
    "from utils.misc import str2bool, Timer, freeze_net_layers, store_labels\n",
    "\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, MultiStepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d78f2aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parser = argparse.ArgumentParser(description='Single Shot MultiBox Detector Training With PyTorch')\n",
    "\n",
    "# Params for datasets\n",
    "parser.add_argument('--datasets', '--data',    nargs='+', default=[\"data\"], help='Dataset directory path')\n",
    "parser.add_argument('--balance-data',          action='store_true', help=\"Balance training data by down-sampling more frequent labels.\")\n",
    "\n",
    "# Params for network\n",
    "parser.add_argument('--freeze-base-net',       action='store_true',help=\"Freeze base net layers.\")\n",
    "parser.add_argument('--freeze-net',            action='store_true',help=\"Freeze all the layers except the prediction head.\")\n",
    "parser.add_argument('--width-mult',            default=1.0, type=float, help='Width Multiplifier for network')\n",
    "\n",
    "# Params for loading pretrained basenet or checkpoints.\n",
    "parser.add_argument('--base-net',              help='Pretrained base model')\n",
    "parser.add_argument('--pretrained',            default='models/pretrained.pth', type=str, help='Pre-trained base model')\n",
    "parser.add_argument('--resume',                default=None, type=str,help='Checkpoint state_dict file to resume training from')\n",
    "\n",
    "# Params for SGD\n",
    "parser.add_argument('--lr', '--learning-rate', default=0.01, type=float,help='initial learning rate')\n",
    "parser.add_argument('--momentum',              default=0.9, type=float,help='Momentum value for optim')\n",
    "parser.add_argument('--weight-decay',          default=5e-4, type=float,help='Weight decay for SGD')\n",
    "parser.add_argument('--gamma',                 default=0.1, type=float,help='Gamma update for SGD')\n",
    "parser.add_argument('--base-net-lr',           default=0.001, type=float,help='initial learning rate for base net, or None to use --lr')\n",
    "parser.add_argument('--extra-layers-lr',       default=None, type=float,help='initial learning rate for the layers not in base net and prediction heads.')\n",
    "\n",
    "# Scheduler\n",
    "parser.add_argument('--scheduler',             default=\"cosine\", type=str,help=\"Scheduler for SGD. It can one of multi-step and cosine\")\n",
    "\n",
    "# Params for Multi-step Scheduler\n",
    "parser.add_argument('--milestones',            default=\"80,100\", type=str,help=\"milestones for MultiStepLR\")\n",
    "\n",
    "# Params for Cosine Annealing\n",
    "parser.add_argument('--t-max',                 default=100,  type=float,help='T_max value for Cosine Annealing Scheduler.')\n",
    "\n",
    "# Train params\n",
    "parser.add_argument('--batch-size',            default=4,    type=int,help='Batch size for training')\n",
    "parser.add_argument('--num-epochs',            default=100,   type=int,help='the number epochs')\n",
    "parser.add_argument('--num-workers',           default=4,    type=int, help='Number of workers used in dataloading')\n",
    "parser.add_argument('--validation-epochs',     default=5,    type=int,help='the number epochs between running validation')\n",
    "parser.add_argument('--debug-steps',           default=10,   type=int,help='Set the debug log output frequency.')\n",
    "parser.add_argument('--use-cuda',              default=True, type=str2bool,help='Use CUDA to train model')\n",
    "parser.add_argument('--checkpoint-folder',     default='models/', help='Directory for saving checkpoint models')\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n",
    "                    format='%(asctime)s - %(message)s', datefmt=\"%Y-%m-%d %H:%M:%S\")\n",
    "                    \n",
    "args   = parser.parse_args([])\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() and args.use_cuda else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f021db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_net = lambda num: create_network(num, width_mult=args.width_mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39760a07",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1526643267.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_434/1526643267.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    720 -> 724 / 16\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# 720 -> 724 / 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "889f7dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12828, 4])\n"
     ]
    }
   ],
   "source": [
    "config.image_size = 720\n",
    "print(config.priors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bc78c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.priors[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03093d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.box_utils import  generate_priors, Spec, BoxSizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ffe3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_size = 600\n",
    "image_size = 720\n",
    "specs = [\n",
    "#     Spec(19, 16, BoxSizes(60, 105), [2, 3]),\n",
    "    Spec(10, 32, BoxSizes(105, 150), [2, 3]),\n",
    "#     Spec(5, 64,  BoxSizes(150, 195), [2, 3]),\n",
    "#     Spec(3, 100, BoxSizes(195, 240), [2, 3]),\n",
    "#     Spec(2, 150, BoxSizes(240, 285), [2, 3]),\n",
    "#     Spec(1, 300, BoxSizes(285, 330), [2, 3])\n",
    "]\n",
    "\n",
    "# specs = [ # 640\n",
    "#     Spec(40, 16, BoxSizes(60, 105), [2, 3]),\n",
    "#     Spec(20, 32, BoxSizes(105, 150), [2, 3]),\n",
    "#     Spec(9, 64, BoxSizes(150, 195), [2, 3]),\n",
    "#     Spec(6, 100, BoxSizes(195, 240), [2, 3]),\n",
    "#     Spec(4, 150, BoxSizes(240, 285), [2, 3]),\n",
    "#     Spec(2, 300, BoxSizes(285, 330), [2, 3]),\n",
    "#     Spec(1, 600, BoxSizes(285, 330), [2, 3]),\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b5305d",
   "metadata": {},
   "outputs": [],
   "source": [
    "priors = generate_priors(specs, image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c97688",
   "metadata": {},
   "outputs": [],
   "source": [
    "priors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea4ca6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#17028"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e40646",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4558d23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform  = TrainAugmentation(config.image_size, config.image_mean, config.image_std)\n",
    "target_transform = MatchPrior(config.priors, config.center_variance,config.size_variance, 0.5)\n",
    "test_transform   = TestTransform(config.image_size, config.image_mean, config.image_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46922205",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.datasets = \"data/person_dog/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2937a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-17 18:06:29 - loading annotations from: data/person_dog/sub-train-annotations-bbox.csv\n",
      "2022-07-17 18:06:29 - annotations loaded from:  data/person_dog/sub-train-annotations-bbox.csv\n",
      "2022-07-17 18:06:37 - missing ImageID 000000235832.jpg - dropping from annotations\n",
      "num images:  75141\n"
     ]
    }
   ],
   "source": [
    "dataset = OpenImagesDataset(args.datasets,\n",
    "                            transform        = train_transform, \n",
    "                            target_transform = target_transform,\n",
    "                            dataset_type     = \"train\",\n",
    "                            balance_data     = args.balance_data\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a1664e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-17 18:06:50 - Dataset Summary:Number of Images: 75141\n",
      "Minimum Number of Images for a Class: -1\n",
      "Label Distribution:\n",
      "\tDog: 4269\n",
      "\tPerson: 271395\n"
     ]
    }
   ],
   "source": [
    "label_file  = os.path.join(args.checkpoint_folder, \"labels.txt\")\n",
    "store_labels(label_file, dataset.class_names)\n",
    "logging.info(dataset)\n",
    "num_classes = len(dataset.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01aab410",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader  = DataLoader(dataset, \n",
    "                           args.batch_size,\n",
    "                           num_workers = args.num_workers,\n",
    "                           shuffle     = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44e17b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "net        = create_net(num_classes)\n",
    "min_loss   = -10000.0\n",
    "last_epoch = -1\n",
    "\n",
    "# freeze certain layers (if requested)\n",
    "base_net_lr = args.base_net_lr if args.base_net_lr is not None else args.lr\n",
    "extra_layers_lr = args.extra_layers_lr if args.extra_layers_lr is not None else args.lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a4da7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "        {'params': net.base_net.parameters(), 'lr': base_net_lr},\n",
    "        {'params': itertools.chain(\n",
    "            net.source_layer_add_ons.parameters(),\n",
    "            net.extras.parameters()\n",
    "        ), 'lr': extra_layers_lr},\n",
    "        {'params': itertools.chain(\n",
    "            net.regression_headers.parameters(),\n",
    "            net.classification_headers.parameters()\n",
    "        )}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cda46805",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/cuda/__init__.py:145: UserWarning: \n",
      "NVIDIA GeForce RTX 3090 with CUDA capability sm_86 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n",
      "If you want to use the NVIDIA GeForce RTX 3090 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaseNetwork(\n",
       "  (base_net): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "        (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "        (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): Sequential(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (extras): ModuleList(\n",
       "    (0): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classification_headers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576)\n",
       "      (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6()\n",
       "      (3): Conv2d(576, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6()\n",
       "      (3): Conv2d(1280, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6()\n",
       "      (3): Conv2d(512, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6()\n",
       "      (3): Conv2d(256, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6()\n",
       "      (3): Conv2d(256, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (5): Conv2d(64, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (regression_headers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576)\n",
       "      (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6()\n",
       "      (3): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6()\n",
       "      (3): Conv2d(1280, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6()\n",
       "      (3): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6()\n",
       "      (3): Conv2d(256, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6()\n",
       "      (3): Conv2d(256, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (5): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (source_layer_add_ons): ModuleList()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.init_from_pretrained(args.pretrained)\n",
    "net.train(True)\n",
    "net.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a774061",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(train_loader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a0d3b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, boxes, labels = data\n",
    "images                = images.to(DEVICE)\n",
    "boxes                 = boxes.to(DEVICE)\n",
    "labels                = labels.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee0c3178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 3, 720, 720]),\n",
       " torch.Size([4, 12828, 4]),\n",
       " torch.Size([4, 12828]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape, boxes.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86b66a61",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_434/3434499049.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconfidence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/Rahul/NanoTrain/src/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_net\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_layer_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mend_layer_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0madded_layer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madded_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0;31m# TODO: if statement only here to tell the jit to skip emitting this when it is None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_batches_tracked\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore[has-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_batches_tracked\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[has-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmomentum\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# use cumulative moving average\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                     \u001b[0mexponential_average_factor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_batches_tracked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "confidence, locations = net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff4ed94",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence.shape, locations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0a8931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(train_loader, net, criterion, optimizer,\n",
    "#               device=DEVICE, debug_steps=args.debug_steps, epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1352b46e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761bb22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f218ed7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa71d3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "126a2569",
   "metadata": {},
   "source": [
    "### Train Pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25f2db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader, net, criterion, optimizer, device, debug_steps=100, epoch=-1):\n",
    "    net.train(True)\n",
    "    running_loss = 0.0\n",
    "    running_regression_loss = 0.0\n",
    "    running_classification_loss = 0.0\n",
    "    for i, data in enumerate(loader):\n",
    "        images, boxes, labels = data\n",
    "        images = images.to(device)\n",
    "        boxes = boxes.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        confidence, locations = net(images)\n",
    "        regression_loss, classification_loss = criterion(confidence, locations, labels, boxes)  # TODO CHANGE BOXES\n",
    "        loss = regression_loss + classification_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_regression_loss += regression_loss.item()\n",
    "        running_classification_loss += classification_loss.item()\n",
    "        if i and i % debug_steps == 0:\n",
    "            avg_loss = running_loss / debug_steps\n",
    "            avg_reg_loss = running_regression_loss / debug_steps\n",
    "            avg_clf_loss = running_classification_loss / debug_steps\n",
    "            logging.info(\n",
    "                f\"Epoch: {epoch}, Step: {i}/{len(loader)}, \" +\n",
    "                f\"Avg Loss: {avg_loss:.4f}, \" +\n",
    "                f\"Avg Regression Loss {avg_reg_loss:.4f}, \" +\n",
    "                f\"Avg Classification Loss: {avg_clf_loss:.4f}\"\n",
    "            )\n",
    "            running_loss = 0.0\n",
    "            running_regression_loss = 0.0\n",
    "            running_classification_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be44403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function and optimizer\n",
    "criterion = MultiboxLoss(config.priors, iou_threshold=0.5, neg_pos_ratio=3,\n",
    "                         center_variance=0.1, size_variance=0.2, device=DEVICE)\n",
    "optimizer = torch.optim.SGD(params, lr=args.lr, momentum=args.momentum,\n",
    "                            weight_decay=args.weight_decay)\n",
    "logging.info(f\"Learning rate: {args.lr}, Base net learning rate: {base_net_lr}, \"\n",
    "             + f\"Extra Layers learning rate: {extra_layers_lr}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d0787f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = CosineAnnealingLR(optimizer, args.t_max, last_epoch=last_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d3aa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(last_epoch + 1, args.num_epochs):\n",
    "    scheduler.step()\n",
    "    train(train_loader, net, criterion, optimizer,\n",
    "          device=DEVICE, debug_steps=args.debug_steps, epoch=epoch)\n",
    "    break\n",
    "\n",
    "#     if epoch % args.validation_epochs == 0 or epoch == args.num_epochs - 1:\n",
    "#         val_loss, val_regression_loss, val_classification_loss = test(val_loader, net, criterion, DEVICE)\n",
    "#         logging.info(\n",
    "#             f\"Epoch: {epoch}, \" +\n",
    "#             f\"Validation Loss: {val_loss:.4f}, \" +\n",
    "#             f\"Validation Regression Loss {val_regression_loss:.4f}, \" +\n",
    "#             f\"Validation Classification Loss: {val_classification_loss:.4f}\"\n",
    "#         )\n",
    "#         model_path = os.path.join(args.checkpoint_folder, f\"{args.net}-Epoch-{epoch}-Loss-{val_loss}.pth\")\n",
    "#         net.save(model_path)\n",
    "#         logging.info(f\"Saved model {model_path}\")\n",
    "\n",
    "# logging.info(\"Task done, exiting program.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89daa6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb629168",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(os.listdir(\"data/person_dog/train\")):\n",
    "    img = cv2.imread(\"data/person_dog/train/\"+i)\n",
    "    if len(img.shape)!=3:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1270fc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"data/person_dog/train/000000235832.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027555e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm data/person_dog/train/000000235832.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccf566b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc55f8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls data/person_dog/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9aaa067",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/person_dog/sub-train-annotations-bbox.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88143c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"ImageID\"]!= \"000000235832\"].to_csv('data/person_dog/sub-train-annotations-bbox.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37805432",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994f4c67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
