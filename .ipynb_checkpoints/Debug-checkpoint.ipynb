{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c9dc6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libs\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import logging\n",
    "import argparse\n",
    "import itertools\n",
    "\n",
    "from src.config import config\n",
    "from src.base import MatchPrior\n",
    "from src.network import create_network\n",
    "from src.multibox_loss import MultiboxLoss\n",
    "from src.open_images import OpenImagesDataset\n",
    "from src.data_preprocessing import TrainAugmentation, TestTransform\n",
    "from utils.misc import str2bool, Timer, freeze_net_layers, store_labels\n",
    "\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, MultiStepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d692cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parser = argparse.ArgumentParser(description='Single Shot MultiBox Detector Training With PyTorch')\n",
    "\n",
    "# Params for datasets\n",
    "parser.add_argument('--datasets', '--data',    nargs='+', default=[\"data\"], help='Dataset directory path')\n",
    "parser.add_argument('--balance-data',          action='store_true', help=\"Balance training data by down-sampling more frequent labels.\")\n",
    "\n",
    "# Params for network\n",
    "parser.add_argument('--freeze-base-net',       action='store_true',help=\"Freeze base net layers.\")\n",
    "parser.add_argument('--freeze-net',            action='store_true',help=\"Freeze all the layers except the prediction head.\")\n",
    "parser.add_argument('--width-mult',            default=1.0, type=float, help='Width Multiplifier for network')\n",
    "\n",
    "# Params for loading pretrained basenet or checkpoints.\n",
    "parser.add_argument('--base-net',              help='Pretrained base model')\n",
    "parser.add_argument('--pretrained',            default='models/pretrained.pth', type=str, help='Pre-trained base model')\n",
    "parser.add_argument('--resume',                default=None, type=str,help='Checkpoint state_dict file to resume training from')\n",
    "\n",
    "# Params for SGD\n",
    "parser.add_argument('--lr', '--learning-rate', default=0.01, type=float,help='initial learning rate')\n",
    "parser.add_argument('--momentum',              default=0.9, type=float,help='Momentum value for optim')\n",
    "parser.add_argument('--weight-decay',          default=5e-4, type=float,help='Weight decay for SGD')\n",
    "parser.add_argument('--gamma',                 default=0.1, type=float,help='Gamma update for SGD')\n",
    "parser.add_argument('--base-net-lr',           default=0.001, type=float,help='initial learning rate for base net, or None to use --lr')\n",
    "parser.add_argument('--extra-layers-lr',       default=None, type=float,help='initial learning rate for the layers not in base net and prediction heads.')\n",
    "\n",
    "# Scheduler\n",
    "parser.add_argument('--scheduler',             default=\"cosine\", type=str,help=\"Scheduler for SGD. It can one of multi-step and cosine\")\n",
    "\n",
    "# Params for Multi-step Scheduler\n",
    "parser.add_argument('--milestones',            default=\"80,100\", type=str,help=\"milestones for MultiStepLR\")\n",
    "\n",
    "# Params for Cosine Annealing\n",
    "parser.add_argument('--t-max',                 default=100,  type=float,help='T_max value for Cosine Annealing Scheduler.')\n",
    "\n",
    "# Train params\n",
    "parser.add_argument('--batch-size',            default=64,    type=int,help='Batch size for training')\n",
    "parser.add_argument('--num-epochs',            default=100,   type=int,help='the number epochs')\n",
    "parser.add_argument('--num-workers',           default=4,    type=int, help='Number of workers used in dataloading')\n",
    "parser.add_argument('--validation-epochs',     default=5,    type=int,help='the number epochs between running validation')\n",
    "parser.add_argument('--debug-steps',           default=10,   type=int,help='Set the debug log output frequency.')\n",
    "parser.add_argument('--use-cuda',              default=True, type=str2bool,help='Use CUDA to train model')\n",
    "parser.add_argument('--checkpoint-folder',     default='models/', help='Directory for saving checkpoint models')\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n",
    "                    format='%(asctime)s - %(message)s', datefmt=\"%Y-%m-%d %H:%M:%S\")\n",
    "                    \n",
    "args   = parser.parse_args([])\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() and args.use_cuda else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "185b2d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(balance_data=False, base_net=None, base_net_lr=0.001, batch_size=4, checkpoint_folder='models/', datasets=['data'], debug_steps=10, extra_layers_lr=None, freeze_base_net=False, freeze_net=False, gamma=0.1, lr=0.01, milestones='80,100', momentum=0.9, num_epochs=30, num_workers=2, pretrained='models/pretrained.pth', resume=None, scheduler='cosine', t_max=100, use_cuda=True, validation_epochs=1, weight_decay=0.0005, width_mult=1.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "274033f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jul 10 10:39:36 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 450.142.00   Driver Version: 450.142.00   CUDA Version: 11.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   32C    P0    26W / 300W |      2MiB / 16160MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e0753c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture:        x86_64\r\n",
      "CPU op-mode(s):      32-bit, 64-bit\r\n",
      "Byte Order:          Little Endian\r\n",
      "CPU(s):              8\r\n",
      "On-line CPU(s) list: 0-7\r\n",
      "Thread(s) per core:  2\r\n",
      "Core(s) per socket:  4\r\n",
      "Socket(s):           1\r\n",
      "NUMA node(s):        1\r\n",
      "Vendor ID:           GenuineIntel\r\n",
      "CPU family:          6\r\n",
      "Model:               79\r\n",
      "Model name:          Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz\r\n",
      "Stepping:            1\r\n",
      "CPU MHz:             2701.581\r\n",
      "CPU max MHz:         3000.0000\r\n",
      "CPU min MHz:         1200.0000\r\n",
      "BogoMIPS:            4600.04\r\n",
      "Hypervisor vendor:   Xen\r\n",
      "Virtualization type: full\r\n",
      "L1d cache:           32K\r\n",
      "L1i cache:           32K\r\n",
      "L2 cache:            256K\r\n",
      "L3 cache:            46080K\r\n",
      "NUMA node0 CPU(s):   0-7\r\n",
      "Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single pti fsgsbase bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx xsaveopt\r\n"
     ]
    }
   ],
   "source": [
    "!lscpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cc8a27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
